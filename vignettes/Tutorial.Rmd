---
title: "MetaR2M Tutorial"
author: "Zhichao Xu, and Peng Wei"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
    %\VignetteIndexEntry{crSKAT Tutorial}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
---

## Introduction 
The [MetaR2M](https://github.com/zhichaoxu04/MetaR2M) `R` package presents a groundbreaking framework for conducting meta-analyses in high-dimensional settings, specifically for evaluating the R2-based total mediation effect. This innovative tool supports both fixed-effects and random-effects models, accommodating various research designs and high-throughput technologies. It is uniquely designed to handle the complexities inherent in high-dimensional data, a common feature in contemporary biomedical research.

Meta-analysis is a statistical technique used to combine the results of multiple studies to arrive at a comprehensive understanding of a particular field or topic. This method is especially prevalent in fields like medicine, psychology, and social sciences, where individual studies might have varying outcomes or small sample sizes. By aggregating data from several studies, a meta-analysis can provide more robust conclusions, identify patterns, and offer insights that might not be apparent from individual studies.

Fixed-effects models require the assumption that the true effects of interest are identical across all studies or cohorts. Random-effects models are used when there is heterogeneity across the studies included in the meta-analysis. In meta-analysis, the choice between a fixed-effect and a random-effects model is fundamental and depends on the underlying assumptions about the nature of the effects being analyzed.

The fixed-effect model operates under the assumption that there is one true effect size that is common to all the studies being analyzed. In essence, it posits that any observed differences in effect sizes across studies are solely due to sampling error. This model is particularly appropriate when the meta-analysis includes studies that are highly similar in terms of participants, interventions, and outcomes, suggesting that they are all tapping into the same underlying effect. The key advantage of this model is its simplicity and increased statistical power due to the assumption of a single underlying effect. However, its major limitation is that it cannot account for variability beyond chance among different studies, which can lead to biased results if this assumption is violated.

On the other hand, the random-effects model acknowledges and accommodates heterogeneity in effect sizes across studies. This model assumes that the studies in the meta-analysis are estimating different, yet related, effect sizes. These differences could arise from variations in study populations, methodologies, or other contextual factors. The random-effects model includes both within-study sampling error and between-study variance in its calculations. This approach is more flexible and realistic in scenarios where study heterogeneity is expected. It provides a more generalized conclusion, applicable to a broader context beyond the specific studies included in the meta-analysis. The trade-off, however, is that this model often has less statistical power compared to the fixed-effect model due to the additional variance component that needs to be estimated.


## Get started
Download and install following required R packages:

- Download [MetaR2M](https://github.com/zhichaoxu04/MetaR2M) package from Github using:

<!-- -->

    git clone https://github.com/zhichaoxu04/crSKAT.git

- Or, install [MetaR2M](https://github.com/zhichaoxu04/MetaR2M) package in R directly

  - First, install [devtools](https://devtools.r-lib.org) in R from CRAN:
    ``` r
    install.packages("devtools")
    ```
  - Then, install [MetaR2M](https://github.com/zhichaoxu04/MetaR2M) using the `install_github` function and load the package:
    ``` r
    devtools::install_github("zhichaoxu04/MetaR2M")
    library(MetaR2M)
    ```
- Make sure that all the required packages have been installed or updated. Here are some of the required packages:
  - [RsqMed](https://cran.r-project.org/web/packages/RsqMed/index.html): An implementation of calculating the R-squared measure as a total mediation effect size measure and its confidence interval for moderate- or high-dimensional mediator models. It gives an option to filter out non-mediators using variable selection methods. The original R package is directly related to the paper [Yang et al (2021)](https://pubmed.ncbi.nlm.nih.gov/34425752/). The new version contains a choice of using cross-fitting, which is computationally faster. The details of the cross-fitting method are available in our paper [Xu et al (2023)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9934518/).
  - [SIS](https://cran.r-project.org/web/packages/SIS/index.html): Variable selection techniques are essential tools for model selection and estimation in high-dimensional statistical models. Through this publicly available package, they provide a unified environment to carry out variable selection using iterative sure independence screening (SIS) ([Fan and Lv (2008)](https://academic.oup.com/jrsssb/article/70/5/849/7109492)) and all of its variants in generalized linear models ([Fan and Song (2009)](https://projecteuclid.org/journals/annals-of-statistics/volume-38/issue-6/Sure-independence-screening-in-generalized-linear-models-with-NP-dimensionality/10.1214/10-AOS798.full)) and the Cox proportional hazards model ([Fan, Feng and Wu (2010)](https://projecteuclid.org/ebooks/institute-of-mathematical-statistics-collections/Borrowing-Strength--Theory-Powering-Applications--A-Festschrift-for/chapter/High-dimensional-variable-selection-for-Coxs-proportional-hazards-model/10.1214/10-IMSCOLL606)).
  - [HDMT](https://cran.r-project.org/web/packages/HDMT/index.html): A multiple-testing procedure for high-dimensional mediation hypotheses. Mediation analysis is of rising interest in epidemiology and clinical trials. Methods used in the package refer to [James Y. Dai, Janet L. Stanford & Michael LeBlanc (2020)](https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1765785).
  - [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html): A Grammar of Data Manipulation: a fast, consistent tool for working with data frame like objects, both in memory and out of memory.
  - [meta](https://cran.r-project.org/web/packages/meta/index.html): User-friendly general package providing standard methods for meta-analysis and supporting Schwarzer, Carpenter, and RÃ¼cker, ["Meta-Analysis with R" (2015)](https://link.springer.com/book/10.1007/978-3-319-21416-0).

## Toy Example

Let's assume our objective is to study the possible association between a specific gene and the time taken for a fracture to occur. In this context, death acts as the competing risk. To delve into this premise, we'll simulate event times for 5,000 subjects based on a proportional hazards model. Observations will be scheduled at four distinct times: 4, 11, 18, and 25. Each participant's precise observation time will be determined by a random draw from a Uniform(-0.25, 0.25) distribution centered around these predefined times. Furthermore, there's a 10% chance for any participant to miss a scheduled visit.

The genetic dataset will include information on 50 single nucleotide polymorphisms (SNPs) related to the gene in question. For every patient, their minor allele count, which can be 0, 1, or 2, is documented for each of these 50 SNPs. Alongside the genetic data, we also possess details on non-genetic covariates: one being categorical and the other one continuous.

```{r example}
library(crSKAT)
# ---- Initialization of random seed, sample size, the number of SNPs, and parameters
set.seed(1)
n <- 5000
q <- 50
alpha1 <- -0.058
alpha2 <- -0.035
beta1 <- 0.03
beta2 <- log(1 - exp(beta1 / alpha1)) * alpha2

# ---- Generate dataset
# Assume all SNPs have MAF of 0.2 in this toy example
gMat <- matrix(data=rbinom(n=n*q, size=2, prob=0.2), nrow=n)
gSummed <- matrix(data=apply(gMat, 1, sum), ncol=1)
# Two covariates (one categorical and one continuous)
xMat <- matrix(data=c(rbinom(n=n, size=1, prob=0.5), 
                      runif(n=n, min=0, max=10)), 
               nrow=n)
# Observation time windows
obsTimes <- seq(4, 28, 7)
# Generate data
outcomeDat <- crSKAT::genData(seed=2023, n=n, 
                              alpha1=alpha1, alpha2=alpha2, 
                              beta1=beta1, beta2=beta2,
                              obsTimes=obsTimes, probMiss=0.1, 
                              windowHalf=.25)
# Left/right exact time for each subject
lt <- outcomeDat$leftTimes
rt <- outcomeDat$rightTimes
# Indicator of right-censored or not
obsInd <- outcomeDat$deltaVecSimple
# Indicator of competing outcome or primary outcome
deltaVec <- outcomeDat$deltaVec

# ---- Perform inference
# make design matrix with cubic spline terms using one knot
dmats <- crSKAT::makeICdmat(xMat=xMat, lt=lt, rt=rt, 
                            obsInd=obsInd, quant_r=NULL, nKnots=1)
# Fit null model using the genotype information 
# only need to do this once for each genetic set 
# note: there is only gSummed on the SNPs used here, which will be constant
nullFit <- crSKAT::crSKAT_fit_null(init_beta=c(rep(0,10),.001), 
                                   leftDmat=dmats$left_dmat, rightDmat=dmats$right_dmat,
                                   deltaVec=deltaVec, leftTimes=lt, gSummed=gSummed, 
                                   allowSingular=TRUE, method="Broyden")

# Perform the crSKAT and crBurden test
crICSKATOut <- crSKAT::crSKAT(leftDmat=dmats$left_dmat, rightDmat=dmats$right_dmat, 
                              leftTimes=lt,deltaVec=deltaVec, gMat=gMat, 
                              gSummed=gSummed, null_beta=nullFit$beta_fit, 
                              pvalue=TRUE)
# p-value of crSKAT
crICSKATOut$p_SKAT
# p-value of crBurden test
crICSKATOut$p_burden

# --- Test another genotype matrix, we DO NOT need to fit the null model again
# Generate another set of SNPs
gMat <- matrix(data=rbinom(n=n*q, size=2, prob=0.1), nrow=n)
gSummed <- matrix(data=apply(gMat, 1, sum), ncol=1)
# Perform the crSKAT and crBurden test again
crICSKATOut <- crSKAT::crSKAT(leftDmat=dmats$left_dmat, rightDmat=dmats$right_dmat, 
                              leftTimes=lt,deltaVec=deltaVec, gMat=gMat, 
                              gSummed=gSummed, null_beta=nullFit$beta_fit, 
                              pvalue=TRUE)
# p-value of crSKAT
crICSKATOut$p_SKAT
# p-value of crBurden test
crICSKATOut$p_burden
```

## Guided Workflow
To perform the crSKAT/crBurden test using [crSKAT](https://github.com/zhichaoxu04/crSKAT), follow these three steps:

1. Use the `crSKAT::makeICdmat()` function to create the design matrices for the null model in the required format. This action is essential only once for all SNP-sets undergoing tests. The function accepts the following parameters:
    - `xMat`: The matrix representing non-genetic covariates.
    - `lt`: A vector indicating the times on the left side of the interval. For left-censored observations, simply input 0.
    - `rt`: A vector specifying the times on the right side of the interval. Input Inf or any numeric value for right-censored observations.
    - `obsInd`: A vector that denotes if the event was observed before the final follow-up (determining right-censorship). Use 0 if the event was observed before the last follow-up (not right-censored), and 1 otherwise.
    - `quant_r`: This parameter can be utilized to define knot locations for the spline, though it's recommended to leave it unspecified and allow the package to operate automatically.
    - `nKnots`: Represents a scalar defining the number of interior knots. By default, setting it to 1 results in three knots in total, comprising one interior and two endpoint knots.

2. The subsequent step involves fitting the null model. This process is necessary only once for every SNP set under examination. Utilize the `crSKAT::crSKAT_fit_null()` function for this purpose, incorporating the following parameters:
    - `init_beta`: A vector containing initial estimates for the covariates in the design matrices produced by `crSKAT::makeICdmat()`. Supplying a closer approximation of the coefficients can expedite the convergence.
    - `leftDmat` & `rightDmat`: Outputs derived directly from `crSKAT::makeICdmat()`.
    - `deltaVec`: A vector signifying the cause of the event (either cause 1 or 2; or 0 for right-censored).
    - `leftTimes`: Corresponds to the `lt` parameter in `crSKAT::makeICdmat()`.
    - `gSummed`: A vector of the aggregated genotype matrix.
    - `allowSingular`: A boolean indicating if minor adjustments to the Jacobian are permissible when it's singular or excessively ill-conditioned.
    - `method`: Specifies the technique employed for deducing a solution.

3. Once the null model is fitted, the concluding step involves testing each SNP set with the `crSKAT::crSKAT()` function. The `gMat` parameter should represent a genotype matrix. Additionally, you'll require `leftDmat`, `rightDmat`, `leftTimes`, `gSummed`, and `deltaVec`, all of which were previously discussed. Lastly, you'll need `null_beta`, which is directly sourced from `crSKAT::crSKAT_fit_null()`. 

## Notes:
Questions or novel applications? Please let me know! Contact information can be found in the [Github](https://github.com/zhichaoxu04). 
